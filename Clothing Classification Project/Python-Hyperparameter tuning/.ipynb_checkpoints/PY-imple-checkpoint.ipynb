{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc4902b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping: no known devices.\n"
     ]
    }
   ],
   "source": [
    "# Ctrl F  -> RUN ABOVE CODE\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.compat.v1 as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras.applications.xception import decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c046d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\python.exe\n",
      "\n",
      "     active environment : test1\n",
      "    active env location : C:\\Users\\User\\anaconda3\\envs\\test1\n",
      "            shell level : 2\n",
      "       user config file : C:\\Users\\User\\.condarc\n",
      " populated config files : C:\\Users\\User\\.condarc\n",
      "          conda version : 4.10.3\n",
      "    conda-build version : 3.21.6\n",
      "         python version : 3.7.12.final.0\n",
      "       virtual packages : __cuda=11.1=0\n",
      "                          __win=0=0\n",
      "                          __archspec=1=x86_64\n",
      "       base environment : C:\\Users\\User\\anaconda3  (writable)\n",
      "      conda av data dir : C:\\Users\\User\\anaconda3\\etc\\conda\n",
      "  conda av metadata url : None\n",
      "           channel URLs : https://conda.anaconda.org/conda-forge/win-64\n",
      "                          https://conda.anaconda.org/conda-forge/noarch\n",
      "                          https://repo.anaconda.com/pkgs/main/win-64\n",
      "                          https://repo.anaconda.com/pkgs/main/noarch\n",
      "                          https://repo.anaconda.com/pkgs/r/win-64\n",
      "                          https://repo.anaconda.com/pkgs/r/noarch\n",
      "                          https://repo.anaconda.com/pkgs/msys2/win-64\n",
      "                          https://repo.anaconda.com/pkgs/msys2/noarch\n",
      "          package cache : C:\\Users\\User\\anaconda3\\pkgs\n",
      "                          C:\\Users\\User\\.conda\\pkgs\n",
      "                          C:\\Users\\User\\AppData\\Local\\conda\\conda\\pkgs\n",
      "       envs directories : C:\\Users\\User\\anaconda3\\envs\n",
      "                          C:\\Users\\User\\.conda\\envs\n",
      "                          C:\\Users\\User\\AppData\\Local\\conda\\conda\\envs\n",
      "               platform : win-64\n",
      "             user-agent : conda/4.10.3 requests/2.26.0 CPython/3.7.12 Windows/10 Windows/10.0.19041\n",
      "          administrator : False\n",
      "             netrc file : None\n",
      "           offline mode : False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run code to understand the environment and package managmenet better! \n",
    "# It's weird the first time I pip install numba in tf_gpu env it didnt work, \n",
    "#   then I run in base environment it also didnt work (I did restart kernel as well)\n",
    "#   After several attempts, it is working now (after i run the installation in base env)\n",
    "\n",
    "from numba import cuda \n",
    "# Reset GPU Memory allocation \n",
    "device = cuda.get_current_device()\n",
    "device.reset()\n",
    "import sys\n",
    "print(sys.executable)\n",
    "!conda info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "78af93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = VGG16(weights='imagenet', input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "007c7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = r'C:\\Users\\User\\.deeplearning4j\\data\\clothes\\hat\\00d94e21-5891-492e-be0e-792e7338c077.jpg'\n",
    "# load_img(path)\n",
    "# img = load_img(path, target_size=(224, 224))\n",
    "# print(img)\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b68d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.array(img)\n",
    "# X = np.array([x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37242c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = preprocess_input(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "506bfbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred = model.predict(X)\n",
    "# decode_predictions(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50b9dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3068 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
    "\n",
    "train_ds = train_gen.flow_from_directory(\n",
    "    r'C:\\Users\\User\\.deeplearning4j\\data\\clothes', \n",
    "    target_size=(224, 224), \n",
    "    batch_size=16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5479a6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 341 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "val_ds = val_gen.flow_from_directory(\n",
    "    r'C:\\Users\\User\\@Code-ML\\Innates TRAINNING\\PPE PROJECT\\PROJECT-TL\\src\\main\\resources\\test',\n",
    "    target_size=(224, 224),\n",
    "    batch_size=16,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea59dd5d",
   "metadata": {},
   "source": [
    "==================================RUN ABOVE CODE==================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7b6f8",
   "metadata": {},
   "source": [
    "# First Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb629bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate = 0.00005) :\n",
    "    base_model= VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    ##################################################\n",
    "    inputs = keras.Input(shape=(224, 224, 3))   \n",
    "    base = base_model(inputs, training= False)\n",
    "    vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n",
    "    outputs = keras.layers.Dense(3)(inner) \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    ##################################################\n",
    "    \n",
    "    learning_rate = learning_rate\n",
    "    optimizer = keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss = loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b60e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'vgg16-base_model.h5',\n",
    "    save_best_only=True,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max', \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb5165a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = make_model()\n",
    "history = model.fit(train_ds, epochs=10, validation_data = val_ds, callbacks = [checkpoint] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1c998b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('vgg16-base_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = model.predict_generator(val_ds, 92 // 32+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(val_ds.classes, y_pred))\n",
    "print('Classification Report')\n",
    "target_names = ['Cats', 'Dogs', 'Horse']\n",
    "print(classification_report(val_ds.classes, y_pred, target_names=list(train_ds.class_indices.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b0897a",
   "metadata": {},
   "source": [
    "# NEw model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ae9799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(learning_rate = 0.00005) :\n",
    "    base_model= VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    ##################################################\n",
    "    inputs = keras.Input(shape=(224, 224, 3))   \n",
    "    base = base_model(inputs, training= False)\n",
    "    #vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    flatten = keras.layers.Flatten()(base)\n",
    "    inner = keras.layers.Dense(4096, activation= 'relu')(flatten) \n",
    "    inner2 = keras.layers.Dense(1024, activation= 'relu')(inner) \n",
    "    inner3 = keras.layers.Dense(256, activation= 'relu')(inner2) \n",
    "    #inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n",
    "    outputs = keras.layers.Dense(10)(inner3) \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    ##################################################\n",
    "    \n",
    "    learning_rate = learning_rate\n",
    "    optimizer = keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss = loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1219f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'vgg16-base_model.h5',\n",
    "    save_best_only=True,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max', \n",
    ")\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbd07f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data = val_ds, callbacks = [checkpoint] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc42c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88de861",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a2843",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title(\"Momdel's Training accuracy vs Validation accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3174e9a1",
   "metadata": {},
   "source": [
    "# Third model with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(learning_rate = 0.00005) :\n",
    "    base_model= VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    ##################################################\n",
    "    inputs = keras.Input(shape=(224, 224, 3))   \n",
    "    base = base_model(inputs, training= False)\n",
    "    #vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    flatten = keras.layers.Flatten()(base)\n",
    "    inner = keras.layers.Dense(4096, activation= 'relu')(flatten) \n",
    "    dp1 = keras.layers.Dropout(0.2)(inner)\n",
    "    inner2 = keras.layers.Dense(1024, activation= 'relu')(dp1) \n",
    "    inner3 = keras.layers.Dense(256, activation= 'relu')(inner2) \n",
    "    #inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n",
    "    outputs = keras.layers.Dense(10)(inner3) \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    ##################################################\n",
    "    \n",
    "    learning_rate = learning_rate\n",
    "    optimizer = keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss = loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'vgg16-dropout_model.h5',\n",
    "    save_best_only=True,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max', \n",
    ")\n",
    "\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=10, validation_data = val_ds, callbacks = [checkpoint] )\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1ce17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(his):\n",
    "    acc = his.history['accuracy']\n",
    "    val_acc = his.history['val_accuracy']\n",
    "    plt.plot(acc)\n",
    "    plt.plot(val_acc)\n",
    "    plt.title(\"Momdel's Training accuracy vs Validation accuracy\")\n",
    "plot_acc(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc41ab9",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning: Epoch & Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5125917c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.context._EagerDeviceContext at 0x1fe80547e08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I keep getting error, so let's switch to CPU instead \n",
    "tf.device('/cpu:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc5feda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_model(learning_rate = 0.00005) :\n",
    "    base_model= VGG16(weights='imagenet', include_top= False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    ##################################################\n",
    "    inputs = keras.Input(shape=(224, 224, 3))   \n",
    "    base = base_model(inputs, training= False)\n",
    "    #vectors = keras.layers.GlobalAveragePooling2D()(base)\n",
    "    flatten = keras.layers.Flatten()(base)\n",
    "    inner = keras.layers.Dense(4096, activation= 'relu')(flatten) \n",
    "    dp1 = keras.layers.Dropout(0.2)(inner)\n",
    "    inner2 = keras.layers.Dense(1024, activation= 'relu')(dp1) \n",
    "    inner3 = keras.layers.Dense(256, activation= 'relu')(inner2) \n",
    "    #inner = keras.layers.Dense(100, activation= 'relu')(vectors) \n",
    "    outputs = keras.layers.Dense(10)(inner3) \n",
    "    model = keras.Model(inputs, outputs)\n",
    "    ##################################################\n",
    "    \n",
    "    learning_rate = learning_rate\n",
    "    optimizer = keras.optimizers.Adam(learning_rate= learning_rate)\n",
    "    loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(\n",
    "        optimizer=optimizer, \n",
    "        loss = loss, \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    #print(model.summary())\n",
    "    return model \n",
    "\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    'vgg16-dropout_model.h5',\n",
    "    save_best_only=True,\n",
    "    monitor = 'val_accuracy',\n",
    "    mode = 'max', \n",
    ")\n",
    "\n",
    "model = make_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a47c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess =  tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a15e02d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd218823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "100/100 [==============================] - 176s 2s/step - loss: 1.0664 - accuracy: 0.6397 - val_loss: 0.6728 - val_accuracy: 0.7625\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 174s 2s/step - loss: 0.4169 - accuracy: 0.8581 - val_loss: 0.6953 - val_accuracy: 0.7375\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 181s 2s/step - loss: 0.2820 - accuracy: 0.9038 - val_loss: 0.4770 - val_accuracy: 0.8250\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 186s 2s/step - loss: 0.1841 - accuracy: 0.9450 - val_loss: 0.8310 - val_accuracy: 0.7312\n",
      "\n",
      "\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.1334 - accuracy: 0.9586 - val_loss: 0.4730 - val_accuracy: 0.8750\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 167s 2s/step - loss: 0.0852 - accuracy: 0.9762 - val_loss: 0.3828 - val_accuracy: 0.8813\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.0807 - accuracy: 0.9749 - val_loss: 0.6155 - val_accuracy: 0.7937\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - 163s 2s/step - loss: 0.0780 - accuracy: 0.9768 - val_loss: 0.8172 - val_accuracy: 0.7750\n",
      "\n",
      "\n",
      "Epoch 1/4\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.0471 - accuracy: 0.9881 - val_loss: 0.6837 - val_accuracy: 0.7875\n",
      "Epoch 2/4\n",
      "100/100 [==============================] - 156s 2s/step - loss: 0.0253 - accuracy: 0.9937 - val_loss: 0.5621 - val_accuracy: 0.8562\n",
      "Epoch 3/4\n",
      "100/100 [==============================] - 160s 2s/step - loss: 0.0354 - accuracy: 0.9919 - val_loss: 0.8639 - val_accuracy: 0.8125\n",
      "Epoch 4/4\n",
      "100/100 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9787"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\@Code-ML\\\\Innates TRAINNING\\\\PPE PROJECT\\\\PROJECT-TL\\\\src\\\\main\\\\resources\\\\test\\\\dress\\\\07cddef1-1fc8-47e4-a28a-613e60912590.jpg'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\@Code-ML\\\\Innates TRAINNING\\\\PPE PROJECT\\\\PROJECT-TL\\\\src\\\\main\\\\resources\\\\test\\\\dress\\\\07cddef1-1fc8-47e4-a28a-613e60912590.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_5957]\n\nFunction call stack:\ntest_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7244/1844008801.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     history = model.fit(train_ds, epochs=4,steps_per_epoch=100, validation_steps=10, batch_size=16, \n\u001b[1;32m----> 6\u001b[1;33m                         validation_data = val_ds, callbacks = [checkpoint] )\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1224\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m               \u001b[0mreturn_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1226\u001b[1;33m               _use_cached_eval_dataset=True)\n\u001b[0m\u001b[0;32m   1227\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'val_'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1228\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1499\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1501\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1502\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    922\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 3040\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1963\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1964\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1966\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 596\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    597\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  FileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\@Code-ML\\\\Innates TRAINNING\\\\PPE PROJECT\\\\PROJECT-TL\\\\src\\\\main\\\\resources\\\\test\\\\dress\\\\07cddef1-1fc8-47e4-a28a-613e60912590.jpg'\nTraceback (most recent call last):\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\ops\\script_ops.py\", line 249, in __call__\n    ret = func(*args)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\", line 645, in wrapper\n    return func(*args, **kwargs)\n\n  File \"C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 892, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 822, in wrapped_generator\n    for data in generator_fn():\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 948, in generator_fn\n    yield x[i]\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"C:\\Users\\User\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\utils.py\", line 113, in load_img\n    with open(path, 'rb') as f:\n\nFileNotFoundError: [Errno 2] No such file or directory: 'C:\\\\Users\\\\User\\\\@Code-ML\\\\Innates TRAINNING\\\\PPE PROJECT\\\\PROJECT-TL\\\\src\\\\main\\\\resources\\\\test\\\\dress\\\\07cddef1-1fc8-47e4-a28a-613e60912590.jpg'\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_test_function_5957]\n\nFunction call stack:\ntest_function\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "lr_list = [0.01, 0.001, 0.005, 0.0001, 0.0005]\n",
    "for lr in lr_list:\n",
    "    make_model(lr)\n",
    "    history = model.fit(train_ds, epochs=4,steps_per_epoch=100, validation_steps=10, batch_size=16, \n",
    "                        validation_data = val_ds, callbacks = [checkpoint] )\n",
    "    \n",
    "    scores[lr] = history.history\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b096000d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
